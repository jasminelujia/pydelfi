{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interpolate\n",
    "import distributions.priors as priors\n",
    "import getdist\n",
    "from getdist import plots, MCSamples\n",
    "import ndes.ndes as ndes\n",
    "import delfi.delfi as delfi\n",
    "import tensorflow as tf\n",
    "import simulators.cosmic_shear.cosmic_shear as cosmic_shear\n",
    "import pickle\n",
    "import compression.score.score as score\n",
    "from scipy.linalg import block_diag\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP THE PRIOR ###\n",
    "\n",
    "# number of nuisance parameters: must match number of photo-z bins\n",
    "nz = 10\n",
    "\n",
    "# Prior over theta\n",
    "lower = np.array([0, 0.4, 0, 0.4, 0.7])\n",
    "upper = np.array([1, 1.2, 0.1, 1.0, 1.3])\n",
    "prior_mean = np.array([0.3, 0.8, 0.05, 0.70, 0.96])\n",
    "prior_covariance = np.eye(5)*np.array([0.1, 0.1, 0.05, 0.3, 0.3])**2\n",
    "prior = priors.TruncatedGaussian(prior_mean, prior_covariance, lower, upper)\n",
    "\n",
    "# Prior over eta (nuisances)\n",
    "eta_lower = np.ones(nz)*-0.1\n",
    "eta_upper = np.ones(nz)*0.1\n",
    "eta_mean = np.zeros(nz)\n",
    "eta_covariance = np.eye(nz)*0.05**2\n",
    "eta_prior = priors.TruncatedGaussian(eta_mean, eta_covariance, eta_lower, eta_upper)\n",
    "\n",
    "# Joint prior over nuisances and interesting parameters\n",
    "joint_lower = np.concatenate([lower, eta_lower])\n",
    "joint_upper = np.concatenate([upper, eta_upper])\n",
    "joint_mean = np.concatenate([prior_mean, eta_mean])\n",
    "joint_covariance = block_diag(prior_covariance, eta_covariance)\n",
    "joint_prior = priors.TruncatedGaussian(joint_mean, \n",
    "                                       joint_covariance,\n",
    "                                       joint_lower,\n",
    "                                       joint_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP THE SIMULATOR ###\n",
    "\n",
    "# import tomographic n(z)\n",
    "pz = pickle.load(open('simulators/cosmic_shear/pz_euclid.pkl', 'rb'))\n",
    "\n",
    "# Set up the tomography simulations\n",
    "CosmicShearSimulator = cosmic_shear.TomographicCosmicShearPhotoz(pz = pz, lmin = 10, lmax = 3000, n_ell_bins = 10, sigma_e = 0.3, nbar = 30, Area = 15000)\n",
    "\n",
    "# Simulator function: This must be of the form simulator(theta, seed, args) -> simulated data vector\n",
    "def simulator(theta, seed, simulator_args, batch):\n",
    "    \n",
    "    # Draw nuisances from prior\n",
    "    eta_prior = simulator_args[0]\n",
    "    eta = eta_prior.draw()\n",
    "    \n",
    "    return CosmicShearSimulator.simulate(np.concatenate([theta, eta]), seed)\n",
    "simulator_args = [eta_prior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP THE COMPRESSOR ###\n",
    "\n",
    "# Fiducial parameters\n",
    "theta_fiducial = np.array([0.3, 0.8, 0.05, 0.70, 0.96])\n",
    "eta_fiducial = np.zeros(len(pz))\n",
    "\n",
    "# Expected support of Wishart likelihood (fiducial inverse power spectrum)\n",
    "C = CosmicShearSimulator.power_spectrum(np.concatenate([theta_fiducial, eta_fiducial]))\n",
    "Cinv = np.array([np.linalg.inv(C[l,:,:]) for l in range(CosmicShearSimulator.n_ell_bins)])\n",
    "\n",
    "# Degrees of freedom (effective number of modes per band power)\n",
    "nl = CosmicShearSimulator.nl\n",
    "\n",
    "# Calculate derivatives of the expected power spectrum\n",
    "h = np.array(abs(theta_fiducial)*np.array([0.05, 0.05, 0.05, 0.05, 0.05]))\n",
    "dCdt = CosmicShearSimulator.compute_derivatives(np.concatenate([theta_fiducial, eta_fiducial]), h)\n",
    "\n",
    "# Define compression as score-MLE of a Wishart likelihood\n",
    "Compressor = score.Wishart(np.concatenate([theta_fiducial, eta_fiducial]), nl, Cinv, dCdt, prior_mean=joint_mean, prior_covariance=joint_covariance)\n",
    "\n",
    "# Pull out Fisher matrix inverse\n",
    "Finv = Compressor.Finv[0:5,0:5]\n",
    "\n",
    "# Compressor function: This must have the form compressor(data, args) -> compressed summaries (pseudoMLE)\n",
    "def compressor(d, compressor_args):\n",
    "    return Compressor.projected_scoreMLE(d, np.arange(5,15))\n",
    "compressor_args = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD IN THE DATA VECTOR ###\n",
    "#data = compressor(simulator(theta_fiducial, 0, simulator_args), compressor_args)\n",
    "data = compressor(C, compressor_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural density estimator (MAF)\n",
    "MAF = ndes.ConditionalMaskedAutoregressiveFlow(n_inputs=5, n_outputs=5, n_hiddens=[50,50], \n",
    "                                               n_mades=5, act_fun=tf.tanh)\n",
    "\n",
    "# Create the DELFI object\n",
    "DelfiMAF = delfi.Delfi(data, prior, MAF, Finv, theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s'], \n",
    "                       results_dir = \"simulators/cosmic_shear/results_marginal/maf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Fisher pre-training\n",
    "DelfiMAF.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial samples, batch size for population samples, number of populations\n",
    "n_initial = 500\n",
    "n_batch = 500\n",
    "n_populations = 23\n",
    "\n",
    "# Do the SNL training\n",
    "DelfiMAF.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=20, simulator_args=simulator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDN = ndes.MixtureDensityNetwork(n_inputs=5, n_outputs=5, n_components=3, n_hidden=[50,50], activations=[tf.tanh, tf.tanh])\n",
    "\n",
    "# Create the DELFI object\n",
    "DelfiMDN = delfi.Delfi(data, prior, MDN, Finv, theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s'], \n",
    "                       results_dir = \"simulators/cosmic_shear/results_marginal/mdn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Fisher pre-training\n",
    "DelfiMDN.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial samples, batch size for population samples, number of populations\n",
    "n_initial = 500\n",
    "n_batch = 500\n",
    "n_populations = 23\n",
    "\n",
    "# Do the SNL training\n",
    "DelfiMDN.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=20, simulator_args=simulator_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare error ellipses with expected Fisher errors\n",
    "\n",
    "# Generate draws from asymptotic posterior\n",
    "asymptotic_posterior = priors.TruncatedGaussian(theta_fiducial, Finv, lower, upper)\n",
    "\n",
    "samples_asymptotic = np.array([asymptotic_posterior.draw() for i in range(100000)])\n",
    "\n",
    "samples = [DelfiMDN.posterior_samples, samples_asymptotic]\n",
    "mc_samples = [MCSamples(samples=s, names = DelfiMDN.names, labels = DelfiMDN.labels, ranges = DelfiMDN.ranges) for s in samples]\n",
    "\n",
    "# Triangle plot\n",
    "\n",
    "plt.close()\n",
    "columnwidth = 40 # cm\n",
    "aspect = 1.67*2\n",
    "pts_per_inch = 72.27\n",
    "inch_per_cm = 2.54\n",
    "width = columnwidth/inch_per_cm\n",
    "plt.rcParams.update({'figure.figsize': [width, width / aspect],\n",
    "                 'backend': 'pdf',\n",
    "                 'font.size': 14,\n",
    "                 'legend.fontsize': 'small',\n",
    "                 'legend.frameon': False,\n",
    "                 'legend.loc': 'best',\n",
    "                 'lines.markersize': 3,\n",
    "                 'lines.linewidth': .5,\n",
    "                 'axes.linewidth': .5,\n",
    "                 'axes.edgecolor': 'black')\n",
    "\n",
    "\n",
    "g = plots.getSubplotPlotter(width_inch = 12)\n",
    "g.settings.figure_legend_frame = False\n",
    "g.settings.alpha_filled_add=0.6\n",
    "g.settings.axes_fontsize=14\n",
    "g.settings.legend_fontsize=16\n",
    "g.settings.lab_fontsize=20\n",
    "#g.triangle_plot(mc_samples[0], filled_compare=True, normalized=True, legend_labels=['Density estimation likelihood-free inference'], contour_ls = ['-.','-.'], contour_colors=['red','red'])\n",
    "#g.triangle_plot(mc_samples[1], filled_compare=False, normalized=True, legend_labels=['Density estimation likelihood-free inference'], contour_ls = ['-.','-.'], contour_colors=['red','red'])\n",
    "g.triangle_plot(mc_samples, filled_compare=[True,False], normalized=True, legend_labels=['Density estimation likelihood-free inference'], contour_lws = [1, 1], contour_ls = ['-','-.'], contour_colors=['#E41A1C','#377EB8'])\n",
    "\n",
    "for i in range(0, len(samples[0][0,:])):\n",
    "    for j in range(0, i+1):\n",
    "        ax = g.subplots[i,j]\n",
    "        xtl = ax.get_xticklabels()\n",
    "        ax.set_xticklabels(xtl, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()\n",
    "#plt.savefig('../paper_II/plots/contours.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
