{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import distributions.priors as priors\n",
    "import getdist\n",
    "from getdist import plots, MCSamples\n",
    "import ndes.ndes as ndes\n",
    "import delfi.delfi as delfi\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and load in data and simulations...\n",
    "\n",
    "# Fiducial parameters about which data compression was performed\n",
    "theta_fiducial = np.array([0.3, 0.8, 0.05, 0.70, 0.96])\n",
    "\n",
    "# Set up the truncated Gaussian prior...\n",
    "\n",
    "# Prior parameter boundaries\n",
    "lower = np.array([0, 0.4, 0, 0.4, 0.7])\n",
    "upper = np.array([1, 1.2, 0.1, 1.0, 1.3])\n",
    "\n",
    "# Prior mean and covariance\n",
    "prior_mean = np.array([0.3, 0.8, 0.05, 0.70, 0.96])\n",
    "Q = np.eye(5)*np.array([0.1, 0.1, 0.05, 0.3, 0.3])**2\n",
    "\n",
    "# Create prior over parameters\n",
    "prior = priors.TruncatedGaussian(prior_mean, Q, lower, upper)\n",
    "\n",
    "# Import data summaries, simulated data summaries and corresponding parameters, and inverse Fisher matrix...\n",
    "\n",
    "# NOTE: The compressed summaries should be in the form of pseudo maximum-likelihood parameter estimators\n",
    "# ie, if you are using the score of an approximate log-likelihood L, you should use compressed summaries\n",
    "# t = \\theta_\\mathrm{fiducial} + F^{-1}\\nabla L where F is the approximate Fisher matrix\n",
    "\n",
    "# Compressed data vector\n",
    "data = np.genfromtxt('simulators/cosmic_shear/pre_ran_sims/compressed_data.dat')\n",
    "\n",
    "# Parameters at which sims were ran\n",
    "sim_params = np.genfromtxt('simulators/cosmic_shear/pre_ran_sims/simulations_parameters.dat')\n",
    "\n",
    "# Compressed data for each simulation (corresponding to parameters above)\n",
    "sim_data = np.genfromtxt('simulators/cosmic_shear/pre_ran_sims/simulations_compressed_data.dat')\n",
    "\n",
    "# Inverse Fisher matrix: this can be a bit rough, no biggie\n",
    "Finv = np.genfromtxt('simulators/cosmic_shear/pre_ran_sims/Finv.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Delfi object...\n",
    "\n",
    "# Create the neural density estimator (MAF stands for Masked Autoregressive Flow)\n",
    "# NOTE: n_inputs = number of parameters, n_outputs = number of compressed summaries\n",
    "n_ndes = 1\n",
    "NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(n_inputs=5, n_outputs=5, n_hiddens=[50,50], \n",
    "                                               n_mades=5, act_fun=tf.tanh, index = i) for i in range(n_ndes)]\n",
    "\n",
    "# Create the DELFI object\n",
    "DelfiMAF = delfi.Delfi(data, prior, NDEs, Finv, theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s'], \n",
    "                       results_dir = \"simulators/cosmic_shear/results_preran/maf\",\n",
    "                       input_normalization=\"fisher\")\n",
    "\n",
    "# Load in the simulations\n",
    "DelfiMAF.load_simulations(sim_data, sim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do the Fisher pre-training step to inirialize the network\n",
    "DelfiMAF.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "DelfiMAF.train_ndes(training_data=[DelfiMAF.x_train, DelfiMAF.y_train], epochs=500, patience=20, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the same thing but with a Mixture Density Network instead of a MAF\n",
    "\n",
    "# Create the neural density estimator (Masked Autoregressive Flow)\n",
    "# NOTE: n_inputs = number of parameters, n_outputs = number of compressed summaries\n",
    "# n_components = number of Gaussian components in the MDN (3-5 should be plenty)\n",
    "MDN = ndes.MixtureDensityNetwork(n_inputs=5, n_outputs=5, n_components=3, \n",
    "                                 n_hidden=[25,25], activations=[tf.tanh, tf.tanh])\n",
    "\n",
    "# Create the DELFI object\n",
    "DelfiMDN = delfi.Delfi(data, prior, MDN, Finv, theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s'], \n",
    "                       results_dir = \"simulators/cosmic_shear/results_preran/mdn\")\n",
    "\n",
    "# Load in the simulations\n",
    "DelfiMDN.load_simulations(sim_data, sim_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Fisher pre-training step to inirialize the network\n",
    "DelfiMDN.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network\n",
    "DelfiMDN.train(epochs=500, patience=20, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit DelfiMDN.log_posterior(theta_fiducial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit DelfiMDN.sess.run(MDN.L,feed_dict={MDN.input:DelfiMDN.x_train,MDN.y:DelfiMDN.y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.log(DelfiMDN.prior.pdf(theta_fiducial))# + DelfiMDN.nde.eval((np.atleast_2d((theta_fiducial-theta_fiducial)/DelfiMDN.fisher_errors), np.atleast_2d((data-theta_fiducial)/DelfiMDN.fisher_errors)), DelfiMDN.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 5, 5)\n",
    "y = np.linspace(5, 0, 5)\n",
    "np.prod(x > y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the MAF and MDN posteriors against eachother to check they give the same result\n",
    "\n",
    "plt.close()\n",
    "columnwidth = 40 # cm\n",
    "aspect = 1.67*2\n",
    "pts_per_inch = 72.27\n",
    "inch_per_cm = 2.54\n",
    "width = columnwidth/inch_per_cm\n",
    "plt.rcParams.update({'figure.figsize': [width, width / aspect],\n",
    "                 'backend': 'pdf',\n",
    "                 'font.size': 14,\n",
    "                 'legend.fontsize': 'small',\n",
    "                 'legend.frameon': False,\n",
    "                 'legend.loc': 'best',\n",
    "                 'lines.markersize': 3,\n",
    "                 'lines.linewidth': .5,\n",
    "                 'axes.linewidth': .5,\n",
    "                 'axes.edgecolor': 'black'})\n",
    "\n",
    "\n",
    "g = plots.getSubplotPlotter(width_inch = 12)\n",
    "g.settings.figure_legend_frame = False\n",
    "g.settings.alpha_filled_add=0.6\n",
    "g.settings.axes_fontsize=14\n",
    "g.settings.legend_fontsize=16\n",
    "g.settings.lab_fontsize=20\n",
    "\n",
    "names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s']\n",
    "labels = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s']\n",
    "ranges = dict(zip(names, [ [lower[i], upper[i]] for i in range(len(names)) ]))\n",
    "\n",
    "samples = [DelfiMAF.posterior_samples, DelfiMDN.posterior_samples]\n",
    "mc_samples = [MCSamples(samples=s, names = names, labels = labels, ranges = ranges) for s in samples]\n",
    "\n",
    "g.triangle_plot(mc_samples, normalized=True)\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    for j in range(0, i+1):\n",
    "        ax = g.subplots[i,j]\n",
    "        xtl = ax.get_xticklabels()\n",
    "        ax.set_xticklabels(xtl, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0, wspace=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
