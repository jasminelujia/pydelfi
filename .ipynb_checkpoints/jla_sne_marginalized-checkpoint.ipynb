{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interpolate\n",
    "from simulators.jla_supernovae_marginalized.jla import *\n",
    "import simulators.jla_supernovae_marginalized.jla_parser as jla\n",
    "import ndes.nde as nde\n",
    "import distributions.priors as priors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jalsing/Dropbox (Simons Foundation)/science/delfi/DELFI/simulators/jla_supernovae_marginalized/jla_parser.py:9: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  dtype = None, names = True)\n"
     ]
    }
   ],
   "source": [
    "### SET UP FOR SIMULATION CODE ###\n",
    "\n",
    "# Import data\n",
    "jla_data, jla_cmats = jla.b14_parse(z_min=None, z_max=None, qual_cut=False,\n",
    "                                    jla_path='simulators/jla_supernovae_marginalized/jla_data/')\n",
    "data = jla_data['mb']\n",
    "delta_m_cut = 10\n",
    "auxiliary_data = np.column_stack([jla_data['zcmb'], jla_data['x1'], jla_data['color'], np.array([(jla_data['3rdvar'] > delta_m_cut)], dtype=int)[0]])\n",
    "\n",
    "# Om, w0, M_b, alpha, beta, delta_m\n",
    "npar = 6\n",
    "theta_fiducial = np.array([  0.20181324,  -0.74762939, -19.04253368,   0.12566322,   2.64387045, -0.05252869])\n",
    "\n",
    "# Define prior limits and boundaries\n",
    "lower = np.array([0, -1.5, -20, 0, 0, -0.5])\n",
    "upper = np.array([0.6, 0, -18, 1, 6, 0.5])\n",
    "Q = np.diag([0.4, 0.75, 0.1, 0.025, 0.25, 0.05])**2\n",
    "Q[0,1] = Q[1,0] = -0.8*0.4*0.75\n",
    "Qinv = np.linalg.inv(Q)\n",
    "prior_mean = np.array([  0.3  ,  -0.75 , -19.05 ,   0.125,   2.6  ,  -0.05 ])\n",
    "prior_args = [prior_mean, Q, lower, upper]\n",
    "\n",
    "# Covariance matrix\n",
    "C = jla.b14_covariance(jla_data, jla_cmats, theta_fiducial[3], theta_fiducial[4])\n",
    "Cinv = np.linalg.inv(C)\n",
    "L = np.linalg.cholesky(C)\n",
    "\n",
    "# Derivative of the covariance matrix\n",
    "n_sn = len(C)\n",
    "dCdt = np.zeros((npar, n_sn, n_sn))\n",
    "\n",
    "# Step size for derivatives\n",
    "step = abs(0.01*theta_fiducial)\n",
    "\n",
    "# N data points\n",
    "ndata = len(jla_data['mb'])\n",
    "\n",
    "# Simulation args\n",
    "sim_args = [auxiliary_data, L]\n",
    "\n",
    "# Compute the mean\n",
    "mu = apparent_magnitude(theta_fiducial, auxiliary_data)\n",
    "\n",
    "# Compute the derivatives\n",
    "dmdt = dmudtheta(theta_fiducial, simulation_seeded, step, npar, ndata, sim_args)\n",
    "dmdt[2,:] = np.ones(n_sn)\n",
    "dmdt[3,:] = -jla_data['x1']\n",
    "dmdt[4,:] = jla_data['color']\n",
    "dmdt[5,:] = (jla_data['3rdvar'] > 10)\n",
    "\n",
    "# Fisher matrix\n",
    "F, Finv = fisher(dmdt, dCdt, Cinv, Qinv, npar)\n",
    "fisher_errors = np.sqrt(np.diag(Finv))\n",
    "\n",
    "# Compute projection vectors\n",
    "Fpinv = np.linalg.inv(F[2:,2:])\n",
    "P1 = np.dot(Fpinv, F[0,2:])\n",
    "P2 = np.dot(Fpinv, F[1,2:])\n",
    "\n",
    "# Simulation args for ABC\n",
    "simABC_args = [theta_fiducial, Finv, Cinv, dmdt, dCdt, mu, Qinv, prior_mean, sim_args, P1, P2, F, prior_args]\n",
    "\n",
    "# Compressed dataset\n",
    "data_observed = mle(theta_fiducial, Finv, Cinv, dmdt, dCdt, mu, Qinv, prior_mean, data)\n",
    "\n",
    "# Do the projection of the data\n",
    "data_observed = np.dot(F, data_observed - theta_fiducial - np.dot(Finv, np.dot(Qinv, prior_mean - theta_fiducial)))\n",
    "data_observed = np.dot(Finv[0:2, 0:2], np.array([data_observed[0] - np.dot(P1, data_observed[2:]), data_observed[1] - np.dot(P2, data_observed[2:])]))\n",
    "data_observed = data_observed + theta_fiducial[:2] + np.dot(Finv[:2,:2], np.dot(Qinv[:2,:2], prior_mean[:2] - theta_fiducial[:2]))\n",
    "data = data_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the simulator function: takes parameters, spits out simulated (compressed) summaries\n",
    "simulator = lambda x: simulationABC(x, simABC_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prior over parameters\n",
    "lower = np.array([0, -1.5])\n",
    "upper = np.array([0.6, 0])\n",
    "Q = np.diag([0.4, 0.75])**2\n",
    "Q[0,1] = Q[1,0] = -0.8*0.4*0.75\n",
    "Qinv = np.linalg.inv(Q)\n",
    "prior_mean = np.array([0.3, -0.75])\n",
    "Finv = Finv[0:2,0:2]\n",
    "theta_fiducial = np.array([0.20181324,  -0.74762939])\n",
    "prior = priors.TruncatedGaussian(prior_mean, Q, lower, upper)\n",
    "\n",
    "# Create asymptotic posterior approximation\n",
    "asymptotic_posterior = priors.TruncatedGaussian(theta_fiducial, Finv, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DELFI MDN object\n",
    "n_components = 1\n",
    "names = ['\\Omega_m', 'w_0']\n",
    "labels =  ['\\\\Omega_m', 'w_0']\n",
    "ranges = {'\\Omega_m':[lower[0], upper[0]], '\\w0':[lower[1], upper[1]]}\n",
    "\n",
    "mdn = nde.DelfiMixtureDensityNetwork(simulator, prior, asymptotic_posterior, Finv, theta_fiducial, data, n_components, n_hidden = [50, 50], activations = ['tanh', 'tanh'], names = names, labels = labels, ranges = ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on the pre-training data...\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "45000/45000 [==============================] - 28s 630us/step - loss: 1.8778 - val_loss: 1.5475\n",
      "Epoch 2/50\n",
      "45000/45000 [==============================] - 29s 647us/step - loss: 1.4754 - val_loss: 1.4444\n",
      "Epoch 3/50\n",
      "45000/45000 [==============================] - 44s 980us/step - loss: 1.4658 - val_loss: 1.4446\n",
      "Epoch 4/50\n",
      "45000/45000 [==============================] - 27s 601us/step - loss: 1.4624 - val_loss: 1.4471\n",
      "Epoch 5/50\n",
      "45000/45000 [==============================] - 27s 595us/step - loss: 1.4582 - val_loss: 1.4493\n",
      "Epoch 6/50\n",
      "45000/45000 [==============================] - 27s 596us/step - loss: 1.4554 - val_loss: 1.4346\n",
      "Epoch 7/50\n",
      "45000/45000 [==============================] - 34s 764us/step - loss: 1.4586 - val_loss: 1.4371\n",
      "Epoch 8/50\n",
      "21800/45000 [=============>................] - ETA: 16s - loss: 1.4478"
     ]
    }
   ],
   "source": [
    "# Proposal for the Fisher pre-training stage\n",
    "proposal = priors.TruncatedGaussian(prior_mean, Q, lower, upper)\n",
    "\n",
    "# Do the Fisher pre-training\n",
    "mdn.fisher_pretraining(50000, proposal, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proposal for the SNL\n",
    "proposal = priors.TruncatedGaussian(theta_fiducial, 9*Finv, lower, upper)\n",
    "\n",
    "# Initial samples, batch size for population samples, number of populations\n",
    "n_initial = 100\n",
    "n_batch = 100\n",
    "n_populations = 7\n",
    "\n",
    "# Do the SNL training\n",
    "mdn.sequential_training(n_initial, n_batch, n_populations, proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plot of the loss as a function of the number of simulations\n",
    "plt.scatter(mdn.n_sim_trace, mdn.loss_trace, s = 20)\n",
    "plt.plot(mdn.n_sim_trace, mdn.loss_trace, color = 'red')\n",
    "plt.xlim(0, mdn.n_sim_trace[-1])\n",
    "plt.xlabel('number of simulations')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
