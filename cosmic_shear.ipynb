{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interpolate\n",
    "import distributions.priors as priors\n",
    "import getdist\n",
    "from getdist import plots, MCSamples\n",
    "import ndes.ndes as ndes\n",
    "import delfi.delfi as delfi\n",
    "import tensorflow as tf\n",
    "import simulators.cosmic_shear.cosmic_shear as cosmic_shear\n",
    "import pickle\n",
    "import compression.score.score as score\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP THE SIMULATOR ###\n",
    "\n",
    "# Set up the tomography simulations\n",
    "pz = pickle.load(open('simulators/cosmic_shear/pz_euclid.pkl', 'rb'))\n",
    "CosmicShearSimulator = cosmic_shear.TomographicCosmicShear(pz = pz, lmin = 10, lmax = 3000, n_ell_bins = 10, \n",
    "                                                           sigma_e = 0.3, nbar = 30, Area = 15000)\n",
    "\n",
    "# Simulator function: This must be of the form simulator(theta, seed, args) -> simulated data vector\n",
    "def simulator(theta, seed, simulator_args, batch):\n",
    "    return CosmicShearSimulator.simulate(theta, seed)\n",
    "\n",
    "# Simulator arguments\n",
    "simulator_args = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP THE PRIOR ###\n",
    "\n",
    "# Define the priors parameters\n",
    "lower = np.array([0, 0.4, 0, 0.4, 0.7])\n",
    "upper = np.array([1, 1.2, 0.1, 1.0, 1.3])\n",
    "prior_mean = np.array([0.3, 0.8, 0.05, 0.70, 0.96])\n",
    "prior_covariance = np.eye(5)*np.array([0.1, 0.1, 0.05, 0.3, 0.3])**2\n",
    "\n",
    "# Prior\n",
    "prior = priors.TruncatedGaussian(prior_mean, prior_covariance, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP THE COMPRESSOR ###\n",
    "\n",
    "# Fiducial parameters\n",
    "theta_fiducial = np.array([0.3, 0.8, 0.05, 0.70, 0.96])\n",
    "\n",
    "# Expected support of Wishart likelihood (fiducial inverse power spectrum)\n",
    "C = CosmicShearSimulator.power_spectrum(theta_fiducial)\n",
    "Cinv = np.array([np.linalg.inv(C[l,:,:]) for l in range(CosmicShearSimulator.n_ell_bins)])\n",
    "\n",
    "# Degrees of freedom (effective number of modes per band power)\n",
    "nl = CosmicShearSimulator.nl\n",
    "\n",
    "# Calculate derivatives of the expected power spectrum\n",
    "h = np.array(abs(theta_fiducial)*np.array([0.05, 0.05, 0.05, 0.05, 0.05]))\n",
    "dCdt = CosmicShearSimulator.compute_derivatives(theta_fiducial, h)\n",
    "\n",
    "# Define compression as score-MLE of a Wishart likelihood\n",
    "Compressor = score.Wishart(theta_fiducial, nl, Cinv, dCdt, prior_mean=prior_mean, prior_covariance=prior_covariance)\n",
    "\n",
    "# Pull out Fisher matrix inverse\n",
    "Finv = Compressor.Finv\n",
    "\n",
    "# Compressor function: This must have the form compressor(data, args) -> compressed summaries (pseudoMLE)\n",
    "def compressor(d, compressor_args):\n",
    "    return Compressor.scoreMLE(d)\n",
    "compressor_args = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD IN THE DATA VECTOR ###\n",
    "data = compressor(simulator(theta_fiducial, 0, simulator_args), compressor_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural density estimator (MAF)\n",
    "MAF = ndes.ConditionalMaskedAutoregressiveFlow(n_inputs=5, n_outputs=5, n_hiddens=[50,50], \n",
    "                                               n_mades=5, act_fun=tf.tanh)\n",
    "\n",
    "#MDN = ndes.MixtureDensityNetwork(n_inputs=5, n_outputs=5, n_components=3, n_hidden=[50,50], activations=[tf.tanh, tf.tanh])\n",
    "\n",
    "# Create the DELFI object\n",
    "DelfiMAF = delfi.Delfi(data, prior, MAF, Finv, theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s'], \n",
    "                       results_dir = \"simulators/cosmic_shear/results/maf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Fisher pre-training\n",
    "DelfiMAF.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial samples, batch size for population samples, number of populations\n",
    "n_initial = 500\n",
    "n_batch = 500\n",
    "n_populations = 23\n",
    "\n",
    "# Do the SNL training\n",
    "DelfiMAF.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the neural density estimator (MDN)\n",
    "MDN = ndes.MixtureDensityNetwork(n_inputs=5, n_outputs=5, n_components=3, n_hidden=[25,25], activations=[tf.tanh, tf.tanh])\n",
    "\n",
    "# Create the DELFI object\n",
    "DelfiMDN = delfi.Delfi(data, prior, MDN, Finv, theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'S_8', '\\Omega_b', 'h', 'n_s'], \n",
    "                       results_dir = \"simulators/cosmic_shear/results/mdn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Fisher pre-training\n",
    "DelfiMDN.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial samples, batch size for population samples, number of populations\n",
    "n_initial = 500\n",
    "n_batch = 500\n",
    "n_populations = 23\n",
    "\n",
    "# Do the SNL training\n",
    "DelfiMDN.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
